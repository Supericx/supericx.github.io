---
layout: post
title: The Bandwidth Problem
description: Why humans aren't the bottleneck we think we are, and how to redesign work for the AI age.
---

I've been thinking a lot about bottlenecks lately.

Not the database kind. The human kind.

Here's something that blew my mind: the human brain processes conscious thought at about 10 bits per second. That's it. Ten bits. Meanwhile, our visual cortex is humming along at 10 million bits per second, effortlessly parsing the world around us.

We're basically running a supercomputer behind our eyes, connected to a dial-up modem for everything else.

This explains so much about why working with AI feels weird. When GPT generates a 10,000-line codebase in seconds, it's not actually making me more productive. It's creating a verification backlog. I still have to read and understand all that code at my pathetically slow 100 bits per second. The AI isn't enhancing my work—it's essentially performing a denial-of-service attack on my brain.

I started calling this the "Bandwidth Inequality." And once you see it, you can't unsee it.

Think about your last AI interaction. How much time did you spend reading walls of text? Scrolling through explanations? Trying to hold multiple concepts in your working memory while the AI casually dumps more information on you?

We've built incredibly powerful AI systems. And we've connected them to humans through... text boxes. It's like having a Ferrari and driving it through a school zone. Forever.

So what's the solution?

I don't think it's "better AI." The AI is already too fast. The solution is redesigning how we work with it.

I've been experimenting with what I call the "Three-Second Rule." If I can't verify or act on AI output within three seconds, something is wrong. Either the output needs to be presented differently, or I'm doing work the AI should be handling.

This led me to a counterintuitive insight: humans shouldn't be information processors. We're terrible at it. What we're actually good at is something much more interesting—agency.

Agency is the belief that you can influence outcomes, combined with the will to act on that belief. It's inherently low-bandwidth. A single strategic decision. A creative leap. A judgment call about what matters.

The best human-AI collaboration I've experienced follows what some researchers call the "Centaur" model. The human is the head—setting direction, making judgments, defining intent. The AI is the body—executing, processing, doing the bandwidth-heavy lifting.

The alternative is the "Cyborg" model, where human and AI are deeply intertwined. Real-time autocomplete. Constant suggestions. It sounds futuristic, but it has a dark side. When the AI is too integrated, humans start to zone out. We become what one paper called "sleeping drivers"—technically in control but not really paying attention.

I've caught myself doing this. Accepting AI suggestions without really reading them. Letting the autocomplete drive while my brain goes on vacation. It feels efficient until you realize you've lost something important—the understanding of why decisions were made.

So here's where I've landed: the future of work isn't about humans doing less. It's about humans doing different things. The high-agency stuff. The judgment calls. The "should we even be doing this?" questions.

Everything else? Let the AI handle it. Not because humans can't do it, but because our bandwidth is too precious to waste on tasks that don't require consciousness.

There's a Japanese concept called Shuhari—learn, break, create. In the AI age, I think it translates to: let the AI handle the "learn" phase (absorbing information), collaborate on the "break" phase (finding edge cases, questioning assumptions), and reserve "create" for the humans (inventing genuinely new things the AI can't imagine because it only knows the past).

I'm still figuring this out. Some days I get the balance right and feel like I'm working at a higher level than ever before. Other days I'm drowning in AI output, desperately trying to verify things at my embarrassing biological clock speed.

But I'm convinced the answer isn't to speed up humans. We've been trying that for centuries and we're still stuck at 10 bits per second. The answer is to redesign everything around that constraint.

Build interfaces that use our visual cortex instead of our reading brain. Create AI systems that act autonomously but report back in dashboards, not documents. Make verification visual—red and green diffs instead of explanations.

Accept that we're the bottleneck. And then design around it.

The goal isn't to keep up with the machines. The goal is to stay human while the machines do everything else.

I think I'm finally okay with being slow.

As long as I'm slow at the right things.
